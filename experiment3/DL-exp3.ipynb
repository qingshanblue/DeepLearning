{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:57:22.299206Z",
     "start_time": "2024-11-25T14:57:21.326452Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手动实现单通道卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:25:12.085693Z",
     "start_time": "2024-11-25T14:25:12.082307Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    \"\"\"\n",
    "    X: 输入, shape (H, W)\n",
    "    K: 卷积核, shape (k_h, k_w)\n",
    "    \"\"\"\n",
    "    H, W = X.shape\n",
    "    k_h, k_w = K.shape\n",
    "    # 初始化结果矩阵\n",
    "    Y = torch.zeros((H - k_h + 1, W - k_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i: i + k_h, j: j + k_w] * K).sum()\n",
    "    return Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:25:21.486186Z",
     "start_time": "2024-11-25T14:25:21.472490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证卷积操作\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = torch.tensor([[0, 1], [2, 3]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手动实现简单单通道卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:26:21.683Z",
     "start_time": "2024-11-25T14:26:21.679363Z"
    }
   },
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        # 初始化卷积层的2个参数：卷积核、偏差\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现填充和步幅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:36:34.587249Z",
     "start_time": "2024-11-25T14:36:34.582266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义一个函数来计算卷积层。它对输入和输出做相应的升维和降维\n",
    "def comp_conv2d(conv2d, X):\n",
    "    # (1, 1)代表批量大小和通道数均为1\n",
    "    X = X.view((1, 1) + X.shape)\n",
    "    Y = conv2d(X)\n",
    "    return Y.view(Y.shape[2:])  # 排除不关心的前两维：批量和通道\n",
    "\n",
    "# 注意这里是两侧分别填充1行或列，所以在两侧一共填充2行或列\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, padding=1, stride=2)\n",
    "X = torch.rand(8, 8)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现输入多通道卷积核"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:32:58.473773Z",
     "start_time": "2024-11-25T14:32:58.470661Z"
    }
   },
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # 输入X：维度(C_in, H, W)\n",
    "    # 卷积核K：维度(C_in, k_h, k_w)\n",
    "    res = corr2d(X[0, :, :], K[0, :, :])\n",
    "    for i in range(1, X.shape[0]):\n",
    "        # 按通道相加\n",
    "        res += corr2d(X[i, :, :], K[i, :, :])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:33:08.162502Z",
     "start_time": "2024-11-25T14:33:08.157092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "                  [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]],\n",
    "                  [[1, 2], [3, 4]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现输出多通道卷积并测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:37:02.558926Z",
     "start_time": "2024-11-25T14:37:02.550983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel shape: torch.Size([4, 3, 3, 3])\n",
      "Y shape: torch.Size([4, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # 对K的第0维遍历，每次同输入X做互相关计算。\n",
    "    # 所有结果使用stack函数合并在一起\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])\n",
    "\n",
    "# X shape: (C_in, H, W)\n",
    "X = torch.arange(192, dtype=torch.float).view((3, 8, 8))\n",
    "# K shape: (C_out, C_in, k_h, k_w)\n",
    "K = torch.arange(108, dtype=torch.float).view((4, 3, 3, 3))\n",
    "print(\"kernel shape:\", K.shape)\n",
    "\n",
    "Y = corr2d_multi_in_out(X, K)\n",
    "print(\"Y shape:\", Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义池化并测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:40:20.390554Z",
     "start_time": "2024-11-25T14:40:20.386942Z"
    }
   },
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    X = X.float()\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:42:20.454870Z",
     "start_time": "2024-11-25T14:42:20.449682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大池化\n",
      "tensor([[4., 5.],\n",
      "        [7., 8.]])\n",
      "平均池化\n",
      "tensor([[2., 3.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# 测试数据\n",
    "X = torch.tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "\n",
    "# 最大池化\n",
    "print(\"最大池化\")\n",
    "print(pool2d(X, (2, 2)))\n",
    "\n",
    "# 平均池化\n",
    "print(\"平均池化\")\n",
    "print(pool2d(X, (2, 2), 'avg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:43:44.541401Z",
     "start_time": "2024-11-25T14:43:44.537965Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(MyConv2D, self).__init__()\n",
    "        # 初始化卷积层的2个参数：卷积核、偏差\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        self.weight = nn.Parameter(torch.randn((out_channels, in_channels) + kernel_size))\n",
    "        self.bias = nn.Parameter(torch.randn(out_channels, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: 输入图片, 维度(batch_size, C_in, H, W)\n",
    "        \"\"\"\n",
    "        return corr2d_multi_in_out(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义一个卷积模块（conv+bn+relu）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:46:16.894663Z",
     "start_time": "2024-11-25T14:46:16.888280Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyConvModule(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(MyConvModule, self).__init__()\n",
    "        # 定义三层卷积\n",
    "        self.conv = nn.Sequential(\n",
    "            MyConv2D(in_channels=3, out_channels=32, kernel_size=3),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 输出层，将通道数变为分类数量\n",
    "        self.fc = nn.Linear(32, num_classes)  # 注意：num_classes需要在外部定义或传入\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 图片先经过三层卷积，输出维度(batch_size, C_out, H, W)\n",
    "        out = self.conv(X)\n",
    "        # 使用平均池化层将图片的大小变为1x1\n",
    "        out = F.avg_pool2d(out, 30)  # 注意：这里的30应该是out.shape[2]，即图片的宽度\n",
    "        # 将张量out从shape batch x 32 x 1 x 1 变为 batch x 32\n",
    "        out = out.squeeze()\n",
    "        # 输入到全连接层将输出的维度变为10\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch定义一个卷积块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:47:39.612595Z",
     "start_time": "2024-11-25T14:47:39.606930Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvModule(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvModule, self).__init__()\n",
    "        # 定义一个三层卷积\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 输出层，将通道数变为分类数量\n",
    "        self.fc = nn.Linear(128, num_classes)  # 注意：num_classes需要在外部定义或传入\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 图片先经过三层卷积，输出维度(batch_size, C_out, H, W)\n",
    "        out = self.conv(X)\n",
    "        # 使用平均池化层将图片的大小变为1x1\n",
    "        out = F.avg_pool2d(out, 26)  # 注意：这里的26应该是out.shape[2]，即图片的宽度\n",
    "        # 将张量out从shape batch x 128 x 1 x 1 变为 batch x 128\n",
    "        out = out.squeeze()\n",
    "        # 输入到全连接层将输出的维度变为10\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:51:37.446338Z",
     "start_time": "2024-11-25T14:51:37.442423Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(net, data_loader, device, optimizer, criterion):\n",
    "    net.train()  # 指定当前为训练模式\n",
    "    train_batch_num = len(data_loader)  # 记录共有多少个batch\n",
    "    total_loss = 0  # 记录Loss\n",
    "    correct = 0  # 记录共有多少个样本被正确分类\n",
    "    sample_num = 0  # 记录样本总数\n",
    "\n",
    "    # 遍历每个batch进行训练\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        batch_idx, (data, target) = batch_idx, (data.to(device), target.to(device))\n",
    "        # 将图片放入指定的device中\n",
    "        data = data.to(device).float()\n",
    "        # 将图片标签放入指定的device中\n",
    "        target = target.to(device).long()\n",
    "        # 将当前梯度清零\n",
    "        optimizer.zero_grad()  # 模型训练 反向传播更新参数\n",
    "        # 使用模型计算出结果\n",
    "        output = net(data)\n",
    "        # 计算损失\n",
    "        loss = criterion(output, target)\n",
    "        # 进行反向传播\n",
    "        loss.backward()\n",
    "        # 更新模型参数\n",
    "        optimizer.step()\n",
    "        # 累加Loss\n",
    "        total_loss += loss.item()\n",
    "        # 找出每个样本值最大的索引，即代表预测此图片属于哪个类别\n",
    "        prediction = torch.argmax(output, 1)\n",
    "        # 统计预测正确的类别数量\n",
    "        correct += (prediction == target).sum().item()\n",
    "        # 累加当前的样本总数\n",
    "        sample_num += len(prediction)\n",
    "\n",
    "    # 计算平均的Loss与准确率\n",
    "    loss = total_loss / train_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义测试函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T14:54:50.804820Z",
     "start_time": "2024-11-25T14:54:50.801548Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_epoch(net, data_loader, device,criterion):\n",
    "    net.eval()  # 指定当前模式为测试模式\n",
    "    test_batch_num = len(data_loader)\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    sample_num = 0\n",
    "    # 指定不进行梯度变化\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            data = data.to(device).float()\n",
    "            target = target.to(device).long()\n",
    "            output = net(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            prediction = torch.argmax(output, 1)\n",
    "            correct += (prediction == target).sum().item()\n",
    "            sample_num += len(prediction)\n",
    "    loss = total_loss / test_batch_num\n",
    "    acc = correct / sample_num\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T14:57:27.074708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"./data\"  # 指定数据的位置\n",
    "# 定义一个transform操作，用户将torch中的数据转换为可以输入到我们模型的形式\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # 首先将数据转换为Tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]\n",
    ")  # 将数据进行归一化\n",
    "\n",
    "# 获取cifar-10数据集并进行transform\n",
    "cifar_train = torchvision.datasets.CIFAR10(\n",
    "    root=data_dir, train=True, download=True, transform=transform\n",
    ")\n",
    "cifar_test = torchvision.datasets.CIFAR10(\n",
    "    root=data_dir, train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# cifar-10数据集对应的10个类别\n",
    "classes = (\n",
    "    \"plane\",\n",
    "    \"car\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    ")\n",
    "num_classes = 10  # 共十类\n",
    "epochs = 100  # 训练多少轮\n",
    "lr = 0.001  # 学习率\n",
    "batch_size = 512  # batch大小\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 生成dataloader\n",
    "cifar_trainloader = torch.utils.data.DataLoader(\n",
    "    cifar_train, batch_size=batch_size, shuffle=True, num_workers=0\n",
    ")\n",
    "cifar_testloader = torch.utils.data.DataLoader(\n",
    "    cifar_test, batch_size=512, shuffle=True, num_workers=0\n",
    ")\n",
    "\n",
    "# 初始化模型\n",
    "# net = MyConvModule().to(device)  # 使用2种方式定义模型\n",
    "net = ConvModule(num_classes).to(device)\n",
    "\n",
    "# 使用多元交叉熵损失\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 使用Adam优化器\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:02:05.767179Z",
     "start_time": "2024-11-25T15:02:05.753113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\t train_loss:1.7261\t train_acc:0.38464\ttest_loss:1.5410\t test_acc:0.456\n",
      "epoch:1\t train_loss:1.3978\t train_acc:0.50904\ttest_loss:1.3985\t test_acc:0.5062\n",
      "epoch:2\t train_loss:1.2681\t train_acc:0.556\ttest_loss:1.4088\t test_acc:0.4905\n",
      "epoch:3\t train_loss:1.1957\t train_acc:0.58116\ttest_loss:1.2616\t test_acc:0.5428\n",
      "epoch:4\t train_loss:1.1381\t train_acc:0.6003\ttest_loss:1.2798\t test_acc:0.5433\n",
      "epoch:5\t train_loss:1.0990\t train_acc:0.61462\ttest_loss:1.3254\t test_acc:0.5515\n",
      "epoch:6\t train_loss:1.0611\t train_acc:0.6295\ttest_loss:1.1369\t test_acc:0.5998\n",
      "epoch:7\t train_loss:1.0271\t train_acc:0.64044\ttest_loss:1.1576\t test_acc:0.5851\n",
      "epoch:8\t train_loss:1.0022\t train_acc:0.64998\ttest_loss:1.2392\t test_acc:0.544\n",
      "epoch:9\t train_loss:0.9761\t train_acc:0.65908\ttest_loss:1.0375\t test_acc:0.6316\n",
      "epoch:10\t train_loss:0.9574\t train_acc:0.66738\ttest_loss:1.2654\t test_acc:0.5559\n",
      "epoch:11\t train_loss:0.9364\t train_acc:0.67478\ttest_loss:1.0485\t test_acc:0.6293\n",
      "epoch:12\t train_loss:0.9264\t train_acc:0.68074\ttest_loss:0.9637\t test_acc:0.6633\n",
      "epoch:13\t train_loss:0.9033\t train_acc:0.687\ttest_loss:1.0443\t test_acc:0.6306\n",
      "epoch:14\t train_loss:0.8917\t train_acc:0.69094\ttest_loss:1.0166\t test_acc:0.6433\n",
      "epoch:15\t train_loss:0.8869\t train_acc:0.68978\ttest_loss:1.0744\t test_acc:0.6163\n",
      "epoch:16\t train_loss:0.8691\t train_acc:0.69934\ttest_loss:1.0562\t test_acc:0.6206\n",
      "epoch:17\t train_loss:0.8557\t train_acc:0.70348\ttest_loss:1.2204\t test_acc:0.583\n",
      "epoch:18\t train_loss:0.8498\t train_acc:0.70652\ttest_loss:0.9905\t test_acc:0.649\n",
      "epoch:19\t train_loss:0.8412\t train_acc:0.7067\ttest_loss:1.0219\t test_acc:0.6466\n",
      "epoch:20\t train_loss:0.8234\t train_acc:0.71546\ttest_loss:1.0012\t test_acc:0.6408\n",
      "epoch:21\t train_loss:0.8172\t train_acc:0.71682\ttest_loss:1.1332\t test_acc:0.6017\n",
      "epoch:22\t train_loss:0.8170\t train_acc:0.71706\ttest_loss:1.0607\t test_acc:0.6263\n",
      "epoch:23\t train_loss:0.8008\t train_acc:0.72226\ttest_loss:1.2065\t test_acc:0.5958\n",
      "epoch:24\t train_loss:0.7908\t train_acc:0.72574\ttest_loss:1.0046\t test_acc:0.641\n",
      "epoch:25\t train_loss:0.7842\t train_acc:0.72868\ttest_loss:1.0971\t test_acc:0.6334\n",
      "epoch:26\t train_loss:0.7758\t train_acc:0.73224\ttest_loss:1.2383\t test_acc:0.6033\n",
      "epoch:27\t train_loss:0.7766\t train_acc:0.73118\ttest_loss:0.9583\t test_acc:0.6625\n",
      "epoch:28\t train_loss:0.7622\t train_acc:0.73776\ttest_loss:0.8737\t test_acc:0.693\n",
      "epoch:29\t train_loss:0.7507\t train_acc:0.73982\ttest_loss:0.9311\t test_acc:0.6717\n",
      "epoch:30\t train_loss:0.7493\t train_acc:0.74124\ttest_loss:1.4022\t test_acc:0.538\n",
      "epoch:31\t train_loss:0.7435\t train_acc:0.74266\ttest_loss:0.9693\t test_acc:0.6647\n",
      "epoch:32\t train_loss:0.7328\t train_acc:0.74742\ttest_loss:1.0643\t test_acc:0.6328\n",
      "epoch:33\t train_loss:0.7323\t train_acc:0.74942\ttest_loss:1.3379\t test_acc:0.577\n",
      "epoch:34\t train_loss:0.7307\t train_acc:0.74732\ttest_loss:1.0576\t test_acc:0.6342\n",
      "epoch:35\t train_loss:0.7215\t train_acc:0.75182\ttest_loss:1.1143\t test_acc:0.6223\n",
      "epoch:36\t train_loss:0.7153\t train_acc:0.75382\ttest_loss:0.8366\t test_acc:0.7075\n",
      "epoch:37\t train_loss:0.7081\t train_acc:0.75766\ttest_loss:1.1645\t test_acc:0.5996\n",
      "epoch:38\t train_loss:0.7077\t train_acc:0.75588\ttest_loss:0.9189\t test_acc:0.6835\n",
      "epoch:39\t train_loss:0.6948\t train_acc:0.7599\ttest_loss:0.9315\t test_acc:0.6839\n",
      "epoch:40\t train_loss:0.6937\t train_acc:0.76246\ttest_loss:0.8736\t test_acc:0.695\n",
      "epoch:41\t train_loss:0.6878\t train_acc:0.7633\ttest_loss:0.9553\t test_acc:0.6714\n",
      "epoch:42\t train_loss:0.6836\t train_acc:0.76484\ttest_loss:0.9789\t test_acc:0.6606\n",
      "epoch:43\t train_loss:0.6812\t train_acc:0.76584\ttest_loss:1.0683\t test_acc:0.645\n",
      "epoch:44\t train_loss:0.6787\t train_acc:0.76732\ttest_loss:1.0669\t test_acc:0.6437\n",
      "epoch:45\t train_loss:0.6694\t train_acc:0.76874\ttest_loss:1.1078\t test_acc:0.6318\n",
      "epoch:46\t train_loss:0.6704\t train_acc:0.76978\ttest_loss:1.4246\t test_acc:0.5563\n",
      "epoch:47\t train_loss:0.6684\t train_acc:0.7701\ttest_loss:0.9362\t test_acc:0.6782\n",
      "epoch:48\t train_loss:0.6613\t train_acc:0.7721\ttest_loss:0.8923\t test_acc:0.6922\n",
      "epoch:49\t train_loss:0.6493\t train_acc:0.77664\ttest_loss:0.9789\t test_acc:0.6639\n",
      "epoch:50\t train_loss:0.6501\t train_acc:0.77768\ttest_loss:1.0830\t test_acc:0.6454\n",
      "epoch:51\t train_loss:0.6484\t train_acc:0.77674\ttest_loss:0.9812\t test_acc:0.6829\n",
      "epoch:52\t train_loss:0.6478\t train_acc:0.77684\ttest_loss:0.9396\t test_acc:0.6783\n",
      "epoch:53\t train_loss:0.6362\t train_acc:0.78316\ttest_loss:0.8803\t test_acc:0.6975\n",
      "epoch:54\t train_loss:0.6397\t train_acc:0.77994\ttest_loss:1.0050\t test_acc:0.6677\n",
      "epoch:55\t train_loss:0.6343\t train_acc:0.78306\ttest_loss:0.9587\t test_acc:0.6747\n",
      "epoch:56\t train_loss:0.6347\t train_acc:0.78384\ttest_loss:1.1465\t test_acc:0.6074\n",
      "epoch:57\t train_loss:0.6352\t train_acc:0.78104\ttest_loss:0.8463\t test_acc:0.7064\n",
      "epoch:58\t train_loss:0.6231\t train_acc:0.78638\ttest_loss:0.9190\t test_acc:0.6916\n",
      "epoch:59\t train_loss:0.6174\t train_acc:0.7884\ttest_loss:0.8897\t test_acc:0.6893\n",
      "epoch:60\t train_loss:0.6153\t train_acc:0.78888\ttest_loss:0.8713\t test_acc:0.7002\n",
      "epoch:61\t train_loss:0.6138\t train_acc:0.7896\ttest_loss:0.9546\t test_acc:0.6661\n",
      "epoch:62\t train_loss:0.6129\t train_acc:0.78998\ttest_loss:0.8545\t test_acc:0.7094\n",
      "epoch:63\t train_loss:0.6072\t train_acc:0.79338\ttest_loss:0.9345\t test_acc:0.6811\n",
      "epoch:64\t train_loss:0.6008\t train_acc:0.79362\ttest_loss:0.8702\t test_acc:0.7093\n",
      "epoch:65\t train_loss:0.5971\t train_acc:0.79594\ttest_loss:1.0488\t test_acc:0.6585\n",
      "epoch:66\t train_loss:0.5918\t train_acc:0.79682\ttest_loss:1.1752\t test_acc:0.6282\n",
      "epoch:67\t train_loss:0.5977\t train_acc:0.79368\ttest_loss:0.8394\t test_acc:0.7128\n",
      "epoch:68\t train_loss:0.5867\t train_acc:0.79806\ttest_loss:0.8448\t test_acc:0.7123\n",
      "epoch:69\t train_loss:0.5882\t train_acc:0.79858\ttest_loss:0.9044\t test_acc:0.6933\n",
      "epoch:70\t train_loss:0.5866\t train_acc:0.79914\ttest_loss:0.9835\t test_acc:0.6772\n",
      "epoch:71\t train_loss:0.5895\t train_acc:0.79794\ttest_loss:0.8328\t test_acc:0.7115\n",
      "epoch:72\t train_loss:0.5823\t train_acc:0.7996\ttest_loss:0.8191\t test_acc:0.7203\n",
      "epoch:73\t train_loss:0.5812\t train_acc:0.80094\ttest_loss:0.9877\t test_acc:0.6713\n",
      "epoch:74\t train_loss:0.5756\t train_acc:0.804\ttest_loss:0.9636\t test_acc:0.6808\n",
      "epoch:75\t train_loss:0.5713\t train_acc:0.80422\ttest_loss:0.7687\t test_acc:0.7422\n",
      "epoch:76\t train_loss:0.5717\t train_acc:0.80474\ttest_loss:0.8617\t test_acc:0.7064\n",
      "epoch:77\t train_loss:0.5697\t train_acc:0.80632\ttest_loss:0.9270\t test_acc:0.6935\n",
      "epoch:78\t train_loss:0.5632\t train_acc:0.80708\ttest_loss:0.8494\t test_acc:0.712\n",
      "epoch:79\t train_loss:0.5602\t train_acc:0.80876\ttest_loss:1.0087\t test_acc:0.6784\n",
      "epoch:80\t train_loss:0.5585\t train_acc:0.80998\ttest_loss:0.7668\t test_acc:0.7413\n",
      "epoch:81\t train_loss:0.5608\t train_acc:0.80802\ttest_loss:0.8146\t test_acc:0.7212\n",
      "epoch:82\t train_loss:0.5518\t train_acc:0.81036\ttest_loss:0.8384\t test_acc:0.7194\n",
      "epoch:83\t train_loss:0.5561\t train_acc:0.80862\ttest_loss:0.9185\t test_acc:0.6928\n",
      "epoch:84\t train_loss:0.5492\t train_acc:0.81088\ttest_loss:1.0422\t test_acc:0.6532\n",
      "epoch:85\t train_loss:0.5470\t train_acc:0.81216\ttest_loss:0.9044\t test_acc:0.6992\n",
      "epoch:86\t train_loss:0.5465\t train_acc:0.81264\ttest_loss:0.8126\t test_acc:0.7231\n",
      "epoch:87\t train_loss:0.5471\t train_acc:0.81438\ttest_loss:1.0168\t test_acc:0.6606\n",
      "epoch:88\t train_loss:0.5415\t train_acc:0.81608\ttest_loss:0.9724\t test_acc:0.6811\n",
      "epoch:89\t train_loss:0.5407\t train_acc:0.81554\ttest_loss:0.9437\t test_acc:0.6969\n",
      "epoch:90\t train_loss:0.5360\t train_acc:0.81732\ttest_loss:1.0017\t test_acc:0.6824\n",
      "epoch:91\t train_loss:0.5400\t train_acc:0.81618\ttest_loss:0.8861\t test_acc:0.7002\n",
      "epoch:92\t train_loss:0.5343\t train_acc:0.81756\ttest_loss:0.7539\t test_acc:0.7442\n",
      "epoch:93\t train_loss:0.5287\t train_acc:0.82012\ttest_loss:0.8388\t test_acc:0.7164\n",
      "epoch:94\t train_loss:0.5241\t train_acc:0.82092\ttest_loss:0.9087\t test_acc:0.7001\n",
      "epoch:95\t train_loss:0.5214\t train_acc:0.82236\ttest_loss:0.8854\t test_acc:0.6998\n",
      "epoch:96\t train_loss:0.5257\t train_acc:0.8206\ttest_loss:0.8627\t test_acc:0.708\n",
      "epoch:97\t train_loss:0.5257\t train_acc:0.82042\ttest_loss:0.8648\t test_acc:0.7102\n",
      "epoch:98\t train_loss:0.5217\t train_acc:0.82086\ttest_loss:0.8241\t test_acc:0.7188\n",
      "epoch:99\t train_loss:0.5160\t train_acc:0.8233\ttest_loss:0.7901\t test_acc:0.7332\n"
     ]
    }
   ],
   "source": [
    "# 存储每一个epoch的Loss与acc的变化，便于后面可视化\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_loss_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 进行训练\n",
    "for epoch in range(epochs):\n",
    "    # 在训练集上训练\n",
    "    train_loss, train_acc = train_epoch(net, data_loader=cifar_trainloader, device=device, optimizer=optimizer, criterion=criterion)\n",
    "    # 在测试集上验证\n",
    "    test_loss, test_acc = test_epoch(net, data_loader=cifar_testloader, device=device, criterion=criterion)\n",
    "    # 保存各个指标\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_acc_list.append(test_acc)\n",
    "    print(f\"epoch:{epoch}\\t train_loss:{train_loss:.4f}\\t train_acc:{train_acc}\\t\"\n",
    "          f\"test_loss:{test_loss:.4f}\\t test_acc:{test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "空洞卷积层实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:03:25.897787Z",
     "start_time": "2024-11-25T15:03:25.893412Z"
    }
   },
   "outputs": [],
   "source": [
    "class DilatedConvModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DilatedConvModule, self).__init__()\n",
    "        # 定义一个空洞率为1, 2, 5的三层空洞卷积\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=0, dilation=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0, dilation=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=0, dilation=5),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # 输出层，将通道数变为分类数量\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 图片先经过三层空洞卷积\n",
    "        out = self.conv(X)\n",
    "        # 使用平均池化层将图片的大小变为1x1\n",
    "        out = F.avg_pool2d(out, 16)\n",
    "        # 将张量out从shape batch x 128 x 1 x 1 变为 batch x 128\n",
    "        out = out.squeeze()\n",
    "        # 输入到全连接层将输出的维度变为10\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残差网络实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T15:04:44.192284Z",
     "start_time": "2024-11-25T15:04:44.188042Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        # 正常卷积部分，堆叠了两层卷积\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        # 如果上方卷积没有改变size和channel\n",
    "        # 则不需要对输入进行变化，故shortcut为空\n",
    "        self.shortcut = nn.Sequential()\n",
    "        # 如果上方卷积改变了size或channel\n",
    "        # 则使用x1卷积改变输入的size和channel，使其保持一致\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 正常使用卷积操作\n",
    "        out = self.left(x)\n",
    "        # 将输入x变换shape后的输入与卷积的输出相加\n",
    "        out += self.shortcut(x)\n",
    "        # 经过激活函数后输出\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/competitions/car-classificationproject-vision/data 车辆分类数据集\n",
    "https://www.kaggle.com/datasets/rajat95gupta/hazing-images-dataset-cvpr-2019 图像去雾数据集"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
