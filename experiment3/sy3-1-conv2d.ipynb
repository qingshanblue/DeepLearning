{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "150d1cf8",
   "metadata": {},
   "source": [
    "# 二维卷积实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b10618",
   "metadata": {},
   "source": [
    "## 0 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82f7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "# --- 1. 自定义测试集 Dataset ---\n",
    "class CustomTestDataset(Dataset):\n",
    "    \"\"\"用于加载无标签测试集（仅返回图像和文件名）\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [\n",
    "            f\n",
    "            for f in os.listdir(root_dir)\n",
    "            if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "        ]\n",
    "        try:\n",
    "            self.image_files.sort(\n",
    "                key=lambda x: int(x.split(\".\")[0].replace(\"image\", \"\"))\n",
    "            )\n",
    "        except ValueError:\n",
    "            self.image_files.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, img_name\n",
    "\n",
    "\n",
    "# --- 2. 改进的数据加载函数（解决验证集Transform问题）---\n",
    "def setup_data_loaders(\n",
    "    data_root: str,\n",
    "    image_size: int = 227,\n",
    "    batch_size: int = 45,\n",
    "    split_ratio: float = 0.8,\n",
    "    num_workers: int = 4,\n",
    ") -> tuple[DataLoader, DataLoader, DataLoader, int]:\n",
    "    \"\"\"\n",
    "    设置和返回训练集、验证集和测试集的数据加载器，以及类别数量。\n",
    "    \n",
    "    关键改进：\n",
    "    - 训练集使用数据增强\n",
    "    - 验证集使用标准预处理（无增强）\n",
    "    - 通过创建两个ImageFolder并用Subset索引的方式实现\n",
    "    \"\"\"\n",
    "\n",
    "    # 2.1 配置路径\n",
    "    TRAIN_DIR = os.path.join(data_root, \"Train/Train\")\n",
    "    TEST_DIR = os.path.join(data_root, \"Test/Test/Test1\")\n",
    "\n",
    "    # ImageNet 标准均值和标准差\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    # 2.2 定义数据预处理\n",
    "    # 训练集：包含数据增强\n",
    "    train_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),  # 添加轻微旋转\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(MEAN, STD),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 验证集和测试集：仅标准预处理，无数据增强\n",
    "    eval_transforms = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(MEAN, STD),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 2.3 关键改进：创建两个ImageFolder实例\n",
    "    # 一个用于训练（带增强），一个用于验证（不带增强）\n",
    "    full_train_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=train_transforms)\n",
    "    full_eval_dataset = datasets.ImageFolder(root=TRAIN_DIR, transform=eval_transforms)\n",
    "    \n",
    "    num_classes = len(full_train_dataset.classes)\n",
    "    total_size = len(full_train_dataset)\n",
    "\n",
    "    # 2.4 计算划分大小\n",
    "    train_size = int(split_ratio * total_size)\n",
    "    val_size = total_size - train_size\n",
    "\n",
    "    # 2.5 生成索引列表（确保训练集和验证集不重叠）\n",
    "    import random\n",
    "    random.seed(42)  # 设置随机种子保证可复现\n",
    "    indices = list(range(total_size))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:]\n",
    "\n",
    "    # 2.6 使用Subset创建数据集\n",
    "    # 训练集使用带增强的transforms\n",
    "    train_dataset = Subset(full_train_dataset, train_indices)\n",
    "    # 验证集使用不带增强的transforms\n",
    "    val_dataset = Subset(full_eval_dataset, val_indices)\n",
    "\n",
    "    # 2.7 创建 DataLoader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # 2.8 加载测试集（无标签）\n",
    "    test_dataset = CustomTestDataset(root_dir=TEST_DIR, transform=eval_transforms)\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    # 打印信息\n",
    "    print(f\"✓ 检测到的类别数量: {num_classes}\")\n",
    "    print(f\"✓ 训练集大小: {len(train_dataset)} (使用数据增强)\")\n",
    "    print(f\"✓ 验证集大小: {len(val_dataset)} (不使用数据增强)\")\n",
    "    print(f\"✓ 测试集大小: {len(test_dataset)}\")\n",
    "    print(f\"✓ 数据加载完成，Batch Size: {batch_size}\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f56c10e",
   "metadata": {},
   "source": [
    "## 1 手写二维卷积的实现，并在至少一个数据集上进行实验，从训练时间、预测精度、Loss变化等角度分析实验结果（最好使用图表展示）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d935a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        chns_in: int,\n",
    "        chns_out: int,\n",
    "        ker_size: int,\n",
    "        nums_classes: int,\n",
    "        device: torch.device,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.chns_in = chns_in\n",
    "        self.chns_out = chns_out\n",
    "        self.ker_size = ker_size\n",
    "        self.nums_classes = nums_classes\n",
    "        self.conv = nn.Sequential(\n",
    "            Model.MyConv2D(self.chns_in, self.chns_out, self.ker_size),\n",
    "            nn.BatchNorm2d(self.chns_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # 形状变为 (N, chns_out, 1, 1)\n",
    "        self.fc = nn.Sequential(nn.Linear(self.chns_out, self.nums_classes))\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        X = self.conv(X)\n",
    "        X = self.avgpool(X)  # 形状变为 (N, chns_out, 1, 1)\n",
    "        X = X.flatten(1)  # 形状变为 (N, chns_out)\n",
    "        X = self.fc(X)\n",
    "        return X\n",
    "\n",
    "    class MyConv2D(nn.Module):\n",
    "        def __init__(self, chns_in: int, chns_out: int, ker_size: int) -> None:\n",
    "            super().__init__()\n",
    "            self.weight = nn.Parameter(\n",
    "                torch.randn(size=(chns_out, chns_in, ker_size, ker_size))\n",
    "            )\n",
    "            self.bias = nn.Parameter(torch.randn(size=(1, chns_out, 1, 1)))\n",
    "\n",
    "        def forward(self, X: torch.Tensor, padding=0, stride=1) -> torch.Tensor:\n",
    "            return (\n",
    "                Model.MyConv2D._corr2d_NCHW(X, self.weight, padding, stride)\n",
    "                + self.bias  # (n,chns_out,(XH-KH+2P)/S,(XW-KW+2P)/S)\n",
    "            )\n",
    "\n",
    "        @staticmethod\n",
    "        def _corr2d_HW(\n",
    "            X_HW: torch.Tensor, K_HW: torch.Tensor, padding: int = 0, stride: int = 1\n",
    "        ) -> torch.Tensor:\n",
    "            # 扩展\n",
    "            if padding > 0:\n",
    "                X_HW = F.pad(X_HW, (padding, padding, padding, padding), \"constant\", 0)\n",
    "            # 计算输出形状\n",
    "            height_X, width_X = X_HW.shape\n",
    "            height_K, width_K = K_HW.shape\n",
    "            H_out = (height_X - height_K) // stride + 1\n",
    "            W_out = (width_X - width_K) // stride + 1\n",
    "            Y = torch.zeros((H_out, W_out), device=X_HW.device)\n",
    "            # 滑动窗口循环\n",
    "            for i in range(H_out):\n",
    "                for j in range(W_out):\n",
    "                    Y[i, j] = (\n",
    "                        X_HW[\n",
    "                            i * stride : i * stride + height_K,\n",
    "                            j * stride : j * stride + width_K,\n",
    "                        ]\n",
    "                        * K_HW\n",
    "                    ).sum()\n",
    "            return Y\n",
    "\n",
    "        @staticmethod\n",
    "        def _corr2d_CHW(\n",
    "            X_CHW: torch.Tensor, K_OIHW: torch.Tensor, padding: int = 0, stride: int = 1\n",
    "        ) -> torch.Tensor:\n",
    "            # 为循环做准备，定好循环次数\n",
    "            chns_in = X_CHW.shape[0]\n",
    "            chns_out = K_OIHW.shape[0]\n",
    "            Y_list = []  # 用于保存每个输出通道的卷积结果\n",
    "            for chn_out in range(chns_out):\n",
    "                K_out = K_OIHW[chn_out]\n",
    "                result = 0  # 用于保存当前输出通道的卷积结果(所有输入通道的卷积结果相加)\n",
    "                for chn_in in range(chns_in):\n",
    "                    Y = Model.MyConv2D._corr2d_HW(\n",
    "                        X_CHW[chn_in], K_out[chn_in], padding, stride\n",
    "                    )\n",
    "                    result += Y\n",
    "                Y_list.append(result)\n",
    "            return torch.stack(Y_list, dim=0)\n",
    "\n",
    "        @staticmethod\n",
    "        def _corr2d_NCHW(\n",
    "            X_NCHW: torch.Tensor, K_OIHW: torch.Tensor, padding: int, stride: int\n",
    "        ) -> torch.Tensor:\n",
    "            nums = X_NCHW.shape[0]\n",
    "            Y_list = []\n",
    "            for n in range(nums):\n",
    "                Y = Model.MyConv2D._corr2d_CHW(X_NCHW[n], K_OIHW, padding, stride)\n",
    "                Y_list.append(Y)\n",
    "            return torch.stack(Y_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4216f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self) -> None:\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def calc(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return self.criterion(y_pred, y_true)\n",
    "\n",
    "    def __call__(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return self.calc(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67558836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, model: Model, lr: float = 0.01) -> None:\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr)\n",
    "\n",
    "    def step(self) -> None:\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe7ae279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model: Model, loss: Loss, data_loader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_nums = 0\n",
    "        data_loss_value, data_acc_value = 0, 0\n",
    "        for features, labels in data_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            predict = model(features)\n",
    "            loss_value = loss(predict, labels)\n",
    "\n",
    "            total_nums += len(labels)\n",
    "            data_loss_value += loss_value.item() * len(labels)\n",
    "            data_acc_value += (predict.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        data_loss_value /= total_nums\n",
    "        data_acc_value /= total_nums\n",
    "    return data_loss_value, data_acc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41a1ccc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: Model,\n",
    "    loss: Loss,\n",
    "    optimizer: Optimizer,\n",
    "    train_loader: DataLoader,\n",
    "    valid_loader: DataLoader,\n",
    "    nnum_epoches: int,\n",
    "    device: torch.device,\n",
    "):\n",
    "    train_loss_list, train_acc_list = [], []\n",
    "    valid_loss_list, valid_acc_list = [], []\n",
    "    for epoch in range(nnum_epoches):\n",
    "        model.train()\n",
    "        total_nums = 0\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "        valid_loss, valid_acc = 0.0, 0.0\n",
    "        # 使用 tqdm 包裹 train_loader\n",
    "        # desc: 设置进度条前面的文字\n",
    "        # leave: 当前 Epoch 完成后是否保留进度条\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{nnum_epoches}\", leave=True)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # 计算预测值和损失值并优化\n",
    "            predict = model(images)\n",
    "            loss_value = loss(predict, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            # 统计数据\n",
    "            total_nums += len(labels)\n",
    "            train_loss += loss_value.item() * len(labels)\n",
    "            train_acc += (predict.argmax(dim=1) == labels).sum().item()\n",
    "            # 实时更新进度条右侧的显示信息\n",
    "            pbar.set_postfix({\"currentBatchLoss\": f\"{loss_value.item():.4f}\"})\n",
    "        # 计算整个 Epoch 的平均值\n",
    "        train_loss /= total_nums\n",
    "        train_acc /= total_nums\n",
    "        valid_loss, valid_acc = evaluation(model, loss, valid_loader, device)\n",
    "        # 3. 打印最终结果（在进度条完成后换行显示）\n",
    "        print(\n",
    "            f\"epoch:{epoch+1}\\r \\\n",
    "              TrainLoss: {train_loss:.4f}, TrainAcc: {train_acc:.4f}\\r \\\n",
    "              ValidLoss: {valid_loss:.4f}, ValidAcc: {valid_acc:.4f}\\r\"\n",
    "        )\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "    return train_loss_list, train_acc_list, valid_loss_list, valid_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b28a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到的类别数量: 45\n",
      "训练集大小: 3240, 验证集大小: 810, 测试集大小: 450\n",
      "--- 数据加载和划分完成 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 1/1620 [07:35<204:38:49, 455.05s/it, currentBatchLoss=4.7537]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m Loss()\n\u001b[0;32m     21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Optimizer(model\u001b[38;5;241m=\u001b[39mmodel, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.003\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m train_loss_list, train_acc_list, valid_loss_list, valid_acc_list \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnnum_epoches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 24\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, loss, optimizer, train_loader, valid_loader, nnum_epoches, device)\u001b[0m\n\u001b[0;32m     22\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 计算预测值和损失值并优化\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss(predict, labels)\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\dev\\conda\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\dev\\conda\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[9], line 24\u001b[0m, in \u001b[0;36mModel.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 24\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(X)  \u001b[38;5;66;03m# 形状变为 (N, chns_out, 1, 1)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# 形状变为 (N, chns_out)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\dev\\conda\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\dev\\conda\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\dev\\conda\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\dev\\conda\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\dev\\conda\\envs\\dl\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[9], line 40\u001b[0m, in \u001b[0;36mModel.MyConv2D.forward\u001b[1;34m(self, X, padding, stride)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: torch\u001b[38;5;241m.\u001b[39mTensor, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m---> 40\u001b[0m         \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMyConv2D\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_corr2d_NCHW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias  \u001b[38;5;66;03m# (n,chns_out,(XH-KH+2P)/S,(XW-KW+2P)/S)\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[9], line 95\u001b[0m, in \u001b[0;36mModel.MyConv2D._corr2d_NCHW\u001b[1;34m(X_NCHW, K_OIHW, padding, stride)\u001b[0m\n\u001b[0;32m     93\u001b[0m Y_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nums):\n\u001b[1;32m---> 95\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMyConv2D\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_corr2d_CHW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_NCHW\u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_OIHW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     Y_list\u001b[38;5;241m.\u001b[39mappend(Y)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(Y_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 81\u001b[0m, in \u001b[0;36mModel.MyConv2D._corr2d_CHW\u001b[1;34m(X_CHW, K_OIHW, padding, stride)\u001b[0m\n\u001b[0;32m     79\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# 用于保存当前输出通道的卷积结果(所有输入通道的卷积结果相加)\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chn_in \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(chns_in):\n\u001b[1;32m---> 81\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMyConv2D\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_corr2d_HW\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_CHW\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchn_in\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchn_in\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\n\u001b[0;32m     85\u001b[0m Y_list\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[9], line 66\u001b[0m, in \u001b[0;36mModel.MyConv2D._corr2d_HW\u001b[1;34m(X_HW, K_HW, padding, stride)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(H_out):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(W_out):\n\u001b[0;32m     60\u001b[0m         Y[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX_HW\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m                \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mheight_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m                \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwidth_K\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mK_HW\u001b[49m\n\u001b[1;32m---> 66\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    DATA_ROOT = (\n",
    "        \"D:/files/works/DeepLearning/experiment3/data/car-classificationproject-vision\"\n",
    "    )\n",
    "    train_loader, val_loader, test_loader, num_classes = setup_data_loaders(\n",
    "        data_root=DATA_ROOT,\n",
    "        image_size=224,\n",
    "        batch_size=2,\n",
    "        split_ratio=0.8,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    model = Model(\n",
    "        chns_in=3,\n",
    "        chns_out=4,\n",
    "        ker_size=3,\n",
    "        nums_classes=45,\n",
    "        device=device,\n",
    "    ).to(device)\n",
    "    loss = Loss()\n",
    "    optimizer = Optimizer(model=model, lr=0.003)\n",
    "    train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = train(\n",
    "        model=model,\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=val_loader,\n",
    "        nnum_epoches=2,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075406e5",
   "metadata": {},
   "source": [
    "## 2 使用torch.nn实现二维卷积，并在至少一个数据集上进行实验，从训练时间、预测精度、Loss变化等角度分析实验结果（最好使用图表展示）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ef198",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        chns_in: int,\n",
    "        chns_base: int,\n",
    "        feats_base: int,\n",
    "        nums_classes: int,\n",
    "        dropout_rate: float,\n",
    "        ker_size: int,\n",
    "        padding: int = 0,\n",
    "        stride: int = 1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.chns_in = chns_in\n",
    "        self.chns_base = chns_base\n",
    "        self.feats_base = feats_base\n",
    "        self.nums_classes = nums_classes\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.ker_size = ker_size\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # cov1\n",
    "            nn.Conv2d(\n",
    "                chns_in,\n",
    "                chns_base * 1,\n",
    "                kernel_size=ker_size,\n",
    "                padding=self.padding,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm2d(chns_base * 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # cov2\n",
    "            nn.Conv2d(\n",
    "                chns_base * 1,\n",
    "                chns_base * 2,\n",
    "                kernel_size=ker_size,\n",
    "                padding=self.padding,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm2d(chns_base * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # conv3\n",
    "            nn.Conv2d(\n",
    "                chns_base * 2,\n",
    "                chns_base * 4,\n",
    "                kernel_size=ker_size,\n",
    "                padding=self.padding,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm2d(chns_base * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # conv4\n",
    "            nn.Conv2d(\n",
    "                chns_base * 4,\n",
    "                chns_base * 8,\n",
    "                kernel_size=ker_size,\n",
    "                padding=self.padding,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm2d(chns_base * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.fc = nn.Sequential(\n",
    "            # fc1\n",
    "            nn.Linear(self.chns_base * 8, self.feats_base),\n",
    "            # nn.BatchNorm1d(self.feats_base),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=self.dropout_rate),\n",
    "            # # fc2\n",
    "            # nn.Linear(self.feats_base, self.feats_base),\n",
    "            # nn.BatchNorm1d(self.feats_base),\n",
    "            # nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=self.dropout_rate),\n",
    "            # fc3\n",
    "            nn.Linear(self.feats_base, self.nums_classes),\n",
    "        )\n",
    "        # 权重初始化\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Kaiming初始化\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        X = self.conv(X)\n",
    "        X = self.pool(X)\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = self.fc(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00dcebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self) -> None:\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def calc(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return self.criterion(y_pred, y_true)\n",
    "\n",
    "    def __call__(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return self.calc(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4b9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(\n",
    "        self, model: Model, lr: float = 0.01, weight_decay: float = 0.01\n",
    "    ) -> None:\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr, weight_decay=weight_decay)\n",
    "\n",
    "    def step(self) -> None:\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c3f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model: Model, loss: Loss, data_loader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_nums = 0\n",
    "        data_loss_value, data_acc_value = 0, 0\n",
    "        for features, labels in data_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            predict = model(features)\n",
    "            loss_value = loss(predict, labels)\n",
    "\n",
    "            total_nums += len(labels)\n",
    "            data_loss_value += loss_value.item() * len(labels)\n",
    "            data_acc_value += (predict.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        data_loss_value /= total_nums\n",
    "        data_acc_value /= total_nums\n",
    "    return data_loss_value, data_acc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eecfd518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: Model,\n",
    "    loss: Loss,\n",
    "    optimizer: Optimizer,\n",
    "    train_loader: DataLoader,\n",
    "    valid_loader: DataLoader,\n",
    "    nnum_epoches: int,\n",
    "    device: torch.device,\n",
    "    accumulation_steps: int,  # 建议传入 4 或 8\n",
    "):\n",
    "    train_loss_list, train_acc_list = [], []\n",
    "    valid_loss_list, valid_acc_list = [], []\n",
    "\n",
    "    # 增加学习率调度器（建议配合梯度累加使用）\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    #     optimizer.optimizer, T_max=nnum_epoches\n",
    "    # )\n",
    "\n",
    "    for epoch in range(nnum_epoches):\n",
    "        model.train()\n",
    "        total_nums = 0\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "\n",
    "        optimizer.zero_grad()  # 在循环开始前清零\n",
    "\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{nnum_epoches}\", leave=True)\n",
    "        for i, (images, labels) in enumerate(pbar):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            predict = model(images)\n",
    "            raw_loss = loss(predict, labels)  # 保存原始 loss 用于统计\n",
    "\n",
    "            # 1. 梯度缩放与反向传播\n",
    "            loss_accumulated = raw_loss / accumulation_steps\n",
    "            loss_accumulated.backward()\n",
    "\n",
    "            # 2. 达到步数更新梯度\n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # 3. 统计数据使用原始 loss (raw_loss)\n",
    "            total_nums += len(labels)\n",
    "            train_loss += raw_loss.item() * len(labels)  # 这里用 raw_loss 保证统计准确\n",
    "            train_acc += (predict.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "            pbar.set_postfix({\"batchLoss\": f\"{raw_loss.item():.4f}\"})\n",
    "\n",
    "        # 4. 处理 Epoch 末尾未达步数的残余梯度\n",
    "        if len(train_loader) % accumulation_steps != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # 计算平均值\n",
    "        train_loss /= total_nums\n",
    "        train_acc /= total_nums\n",
    "\n",
    "        # 5. 更新学习率\n",
    "        # scheduler.step()\n",
    "\n",
    "        valid_loss, valid_acc = evaluation(model, loss, valid_loader, device)\n",
    "\n",
    "        print(\n",
    "            f\"epoch:{epoch+1}\\n\"\n",
    "            f\"TrainLoss: {train_loss:.4f}, TrainAcc: {train_acc:.4f}\\n\"\n",
    "            f\"ValidLoss: {valid_loss:.4f}, ValidAcc: {valid_acc:.4f}\\n\"\n",
    "            f\"LR: {optimizer.optimizer.param_groups[0]['lr']:.6f}\"\n",
    "        )  # 打印当前学习率辅助调试\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "\n",
    "    return train_loss_list, train_acc_list, valid_loss_list, valid_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625ca800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 检测到的类别数量: 45\n",
      "✓ 训练集大小: 3240 (使用数据增强)\n",
      "✓ 验证集大小: 810 (不使用数据增强)\n",
      "✓ 测试集大小: 450\n",
      "✓ 数据加载完成，Batch Size: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/64: 100%|██████████| 102/102 [00:29<00:00,  3.48it/s, batchLoss=3.7035]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "TrainLoss: 3.7411, TrainAcc: 0.0528\n",
      "ValidLoss: 3.6300, ValidAcc: 0.0593\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/64: 100%|██████████| 102/102 [00:34<00:00,  2.94it/s, batchLoss=3.7291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2\n",
      "TrainLoss: 3.5618, TrainAcc: 0.0858\n",
      "ValidLoss: 3.4593, ValidAcc: 0.0975\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/64: 100%|██████████| 102/102 [00:30<00:00,  3.36it/s, batchLoss=3.4708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3\n",
      "TrainLoss: 3.4812, TrainAcc: 0.1056\n",
      "ValidLoss: 3.4139, ValidAcc: 0.1037\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/64: 100%|██████████| 102/102 [00:28<00:00,  3.53it/s, batchLoss=3.9480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4\n",
      "TrainLoss: 3.4322, TrainAcc: 0.1043\n",
      "ValidLoss: 3.3848, ValidAcc: 0.1235\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/64: 100%|██████████| 102/102 [00:29<00:00,  3.44it/s, batchLoss=3.1008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5\n",
      "TrainLoss: 3.3866, TrainAcc: 0.1222\n",
      "ValidLoss: 3.4365, ValidAcc: 0.1235\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/64: 100%|██████████| 102/102 [00:27<00:00,  3.67it/s, batchLoss=3.6208]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6\n",
      "TrainLoss: 3.3370, TrainAcc: 0.1330\n",
      "ValidLoss: 3.3872, ValidAcc: 0.1148\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/64: 100%|██████████| 102/102 [00:28<00:00,  3.60it/s, batchLoss=3.8584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7\n",
      "TrainLoss: 3.3101, TrainAcc: 0.1370\n",
      "ValidLoss: 3.2707, ValidAcc: 0.1469\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/64: 100%|██████████| 102/102 [00:30<00:00,  3.35it/s, batchLoss=3.4622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8\n",
      "TrainLoss: 3.2763, TrainAcc: 0.1457\n",
      "ValidLoss: 3.2842, ValidAcc: 0.1346\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/64: 100%|██████████| 102/102 [00:29<00:00,  3.42it/s, batchLoss=3.5091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9\n",
      "TrainLoss: 3.2202, TrainAcc: 0.1509\n",
      "ValidLoss: 3.2703, ValidAcc: 0.1370\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/64: 100%|██████████| 102/102 [00:29<00:00,  3.43it/s, batchLoss=2.8122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10\n",
      "TrainLoss: 3.1803, TrainAcc: 0.1682\n",
      "ValidLoss: 3.1436, ValidAcc: 0.1889\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/64: 100%|██████████| 102/102 [00:28<00:00,  3.58it/s, batchLoss=3.4988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11\n",
      "TrainLoss: 3.1633, TrainAcc: 0.1623\n",
      "ValidLoss: 3.5488, ValidAcc: 0.1037\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/64: 100%|██████████| 102/102 [00:30<00:00,  3.33it/s, batchLoss=2.8525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12\n",
      "TrainLoss: 3.0955, TrainAcc: 0.1815\n",
      "ValidLoss: 3.1197, ValidAcc: 0.1765\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/64: 100%|██████████| 102/102 [00:28<00:00,  3.53it/s, batchLoss=3.0039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13\n",
      "TrainLoss: 3.0803, TrainAcc: 0.1756\n",
      "ValidLoss: 3.5515, ValidAcc: 0.1321\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/64: 100%|██████████| 102/102 [00:29<00:00,  3.47it/s, batchLoss=3.0094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14\n",
      "TrainLoss: 3.0434, TrainAcc: 0.1988\n",
      "ValidLoss: 3.1673, ValidAcc: 0.1728\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/64: 100%|██████████| 102/102 [00:30<00:00,  3.29it/s, batchLoss=2.5024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15\n",
      "TrainLoss: 3.0050, TrainAcc: 0.1951\n",
      "ValidLoss: 2.9903, ValidAcc: 0.1938\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/64: 100%|██████████| 102/102 [00:28<00:00,  3.62it/s, batchLoss=2.9663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16\n",
      "TrainLoss: 2.9465, TrainAcc: 0.2142\n",
      "ValidLoss: 3.0866, ValidAcc: 0.1840\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/64: 100%|██████████| 102/102 [00:27<00:00,  3.66it/s, batchLoss=3.0294]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17\n",
      "TrainLoss: 2.8896, TrainAcc: 0.2241\n",
      "ValidLoss: 2.9275, ValidAcc: 0.2272\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/64: 100%|██████████| 102/102 [00:30<00:00,  3.38it/s, batchLoss=3.0649]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18\n",
      "TrainLoss: 2.8605, TrainAcc: 0.2333\n",
      "ValidLoss: 3.4440, ValidAcc: 0.1568\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/64: 100%|██████████| 102/102 [00:29<00:00,  3.50it/s, batchLoss=3.3266]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19\n",
      "TrainLoss: 2.8410, TrainAcc: 0.2287\n",
      "ValidLoss: 2.9011, ValidAcc: 0.2333\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/64: 100%|██████████| 102/102 [00:29<00:00,  3.42it/s, batchLoss=3.1683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20\n",
      "TrainLoss: 2.7865, TrainAcc: 0.2503\n",
      "ValidLoss: 3.1283, ValidAcc: 0.1889\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/64: 100%|██████████| 102/102 [00:29<00:00,  3.50it/s, batchLoss=3.2760]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21\n",
      "TrainLoss: 2.7956, TrainAcc: 0.2398\n",
      "ValidLoss: 3.1680, ValidAcc: 0.1753\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/64: 100%|██████████| 102/102 [00:29<00:00,  3.42it/s, batchLoss=3.7307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22\n",
      "TrainLoss: 2.7321, TrainAcc: 0.2611\n",
      "ValidLoss: 3.0079, ValidAcc: 0.2321\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/64: 100%|██████████| 102/102 [00:29<00:00,  3.47it/s, batchLoss=2.7457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23\n",
      "TrainLoss: 2.6886, TrainAcc: 0.2654\n",
      "ValidLoss: 3.3795, ValidAcc: 0.1593\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/64: 100%|██████████| 102/102 [00:30<00:00,  3.38it/s, batchLoss=3.1692]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24\n",
      "TrainLoss: 2.6489, TrainAcc: 0.2698\n",
      "ValidLoss: 2.8769, ValidAcc: 0.2272\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/64: 100%|██████████| 102/102 [00:28<00:00,  3.61it/s, batchLoss=3.3697]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25\n",
      "TrainLoss: 2.6549, TrainAcc: 0.2787\n",
      "ValidLoss: 2.8258, ValidAcc: 0.2370\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/64: 100%|██████████| 102/102 [00:28<00:00,  3.63it/s, batchLoss=2.6763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26\n",
      "TrainLoss: 2.5797, TrainAcc: 0.2889\n",
      "ValidLoss: 2.7693, ValidAcc: 0.2642\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/64: 100%|██████████| 102/102 [00:28<00:00,  3.61it/s, batchLoss=2.7573]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27\n",
      "TrainLoss: 2.5407, TrainAcc: 0.2889\n",
      "ValidLoss: 2.9362, ValidAcc: 0.2432\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/64: 100%|██████████| 102/102 [00:28<00:00,  3.62it/s, batchLoss=3.1698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28\n",
      "TrainLoss: 2.5426, TrainAcc: 0.3003\n",
      "ValidLoss: 3.4746, ValidAcc: 0.1593\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/64: 100%|██████████| 102/102 [00:28<00:00,  3.52it/s, batchLoss=3.7923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29\n",
      "TrainLoss: 2.5417, TrainAcc: 0.2963\n",
      "ValidLoss: 3.1220, ValidAcc: 0.2062\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/64: 100%|██████████| 102/102 [00:28<00:00,  3.52it/s, batchLoss=2.9454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30\n",
      "TrainLoss: 2.4748, TrainAcc: 0.3056\n",
      "ValidLoss: 2.9987, ValidAcc: 0.2160\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/64: 100%|██████████| 102/102 [00:29<00:00,  3.41it/s, batchLoss=3.0219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31\n",
      "TrainLoss: 2.4053, TrainAcc: 0.3349\n",
      "ValidLoss: 3.4283, ValidAcc: 0.2210\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/64: 100%|██████████| 102/102 [00:28<00:00,  3.54it/s, batchLoss=2.2377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32\n",
      "TrainLoss: 2.4000, TrainAcc: 0.3299\n",
      "ValidLoss: 2.6314, ValidAcc: 0.2914\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/64: 100%|██████████| 102/102 [00:28<00:00,  3.55it/s, batchLoss=3.1218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33\n",
      "TrainLoss: 2.3555, TrainAcc: 0.3343\n",
      "ValidLoss: 3.1154, ValidAcc: 0.1926\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/64: 100%|██████████| 102/102 [00:29<00:00,  3.43it/s, batchLoss=2.2576]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34\n",
      "TrainLoss: 2.3300, TrainAcc: 0.3432\n",
      "ValidLoss: 3.4107, ValidAcc: 0.1889\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/64: 100%|██████████| 102/102 [00:28<00:00,  3.52it/s, batchLoss=2.8068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35\n",
      "TrainLoss: 2.2932, TrainAcc: 0.3444\n",
      "ValidLoss: 3.4010, ValidAcc: 0.2000\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/64: 100%|██████████| 102/102 [00:29<00:00,  3.48it/s, batchLoss=2.1056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36\n",
      "TrainLoss: 2.2808, TrainAcc: 0.3596\n",
      "ValidLoss: 3.1580, ValidAcc: 0.2012\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/64: 100%|██████████| 102/102 [00:30<00:00,  3.39it/s, batchLoss=3.2662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37\n",
      "TrainLoss: 2.2437, TrainAcc: 0.3654\n",
      "ValidLoss: 2.7020, ValidAcc: 0.2840\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/64: 100%|██████████| 102/102 [00:30<00:00,  3.40it/s, batchLoss=2.4432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38\n",
      "TrainLoss: 2.2714, TrainAcc: 0.3503\n",
      "ValidLoss: 2.9165, ValidAcc: 0.2790\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/64: 100%|██████████| 102/102 [00:29<00:00,  3.44it/s, batchLoss=2.5998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39\n",
      "TrainLoss: 2.2029, TrainAcc: 0.3728\n",
      "ValidLoss: 3.2863, ValidAcc: 0.2247\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/64: 100%|██████████| 102/102 [00:29<00:00,  3.51it/s, batchLoss=2.2547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40\n",
      "TrainLoss: 2.1933, TrainAcc: 0.3707\n",
      "ValidLoss: 3.1245, ValidAcc: 0.2210\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/64: 100%|██████████| 102/102 [00:28<00:00,  3.58it/s, batchLoss=1.9745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41\n",
      "TrainLoss: 2.1540, TrainAcc: 0.3846\n",
      "ValidLoss: 2.6214, ValidAcc: 0.2988\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/64: 100%|██████████| 102/102 [00:28<00:00,  3.52it/s, batchLoss=2.2338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42\n",
      "TrainLoss: 2.0974, TrainAcc: 0.3988\n",
      "ValidLoss: 2.6750, ValidAcc: 0.2889\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/64: 100%|██████████| 102/102 [00:28<00:00,  3.62it/s, batchLoss=2.5252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43\n",
      "TrainLoss: 2.0834, TrainAcc: 0.4015\n",
      "ValidLoss: 2.6921, ValidAcc: 0.3086\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/64: 100%|██████████| 102/102 [00:28<00:00,  3.56it/s, batchLoss=2.8788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44\n",
      "TrainLoss: 2.0982, TrainAcc: 0.3994\n",
      "ValidLoss: 2.5710, ValidAcc: 0.2988\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/64: 100%|██████████| 102/102 [00:30<00:00,  3.36it/s, batchLoss=3.5691]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45\n",
      "TrainLoss: 2.0496, TrainAcc: 0.4083\n",
      "ValidLoss: 2.5162, ValidAcc: 0.3222\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/64: 100%|██████████| 102/102 [00:34<00:00,  3.00it/s, batchLoss=2.5480]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46\n",
      "TrainLoss: 2.0176, TrainAcc: 0.4130\n",
      "ValidLoss: 2.6971, ValidAcc: 0.3173\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/64: 100%|██████████| 102/102 [00:29<00:00,  3.48it/s, batchLoss=3.1899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47\n",
      "TrainLoss: 2.0114, TrainAcc: 0.4142\n",
      "ValidLoss: 2.4667, ValidAcc: 0.3383\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/64: 100%|██████████| 102/102 [00:30<00:00,  3.33it/s, batchLoss=2.5010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48\n",
      "TrainLoss: 2.0090, TrainAcc: 0.4130\n",
      "ValidLoss: 2.9866, ValidAcc: 0.2543\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/64: 100%|██████████| 102/102 [00:38<00:00,  2.63it/s, batchLoss=2.2342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49\n",
      "TrainLoss: 1.9456, TrainAcc: 0.4383\n",
      "ValidLoss: 2.4567, ValidAcc: 0.3247\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/64: 100%|██████████| 102/102 [00:29<00:00,  3.51it/s, batchLoss=1.4525]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:50\n",
      "TrainLoss: 1.9466, TrainAcc: 0.4324\n",
      "ValidLoss: 2.5914, ValidAcc: 0.3210\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/64: 100%|██████████| 102/102 [00:28<00:00,  3.59it/s, batchLoss=2.5007]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:51\n",
      "TrainLoss: 1.9204, TrainAcc: 0.4318\n",
      "ValidLoss: 3.0707, ValidAcc: 0.2494\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/64: 100%|██████████| 102/102 [00:28<00:00,  3.61it/s, batchLoss=1.5156]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:52\n",
      "TrainLoss: 1.8837, TrainAcc: 0.4373\n",
      "ValidLoss: 2.3696, ValidAcc: 0.3654\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/64: 100%|██████████| 102/102 [00:28<00:00,  3.59it/s, batchLoss=1.9861]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:53\n",
      "TrainLoss: 1.8705, TrainAcc: 0.4534\n",
      "ValidLoss: 2.7571, ValidAcc: 0.2951\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/64: 100%|██████████| 102/102 [00:28<00:00,  3.54it/s, batchLoss=2.1852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:54\n",
      "TrainLoss: 1.8392, TrainAcc: 0.4599\n",
      "ValidLoss: 2.5185, ValidAcc: 0.3185\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/64: 100%|██████████| 102/102 [00:28<00:00,  3.57it/s, batchLoss=2.7475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:55\n",
      "TrainLoss: 1.8404, TrainAcc: 0.4559\n",
      "ValidLoss: 2.3072, ValidAcc: 0.3630\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/64: 100%|██████████| 102/102 [00:28<00:00,  3.56it/s, batchLoss=1.8301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:56\n",
      "TrainLoss: 1.7855, TrainAcc: 0.4741\n",
      "ValidLoss: 3.0277, ValidAcc: 0.2617\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/64: 100%|██████████| 102/102 [00:29<00:00,  3.46it/s, batchLoss=2.2712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:57\n",
      "TrainLoss: 1.7594, TrainAcc: 0.4802\n",
      "ValidLoss: 2.6115, ValidAcc: 0.3407\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/64: 100%|██████████| 102/102 [00:27<00:00,  3.72it/s, batchLoss=1.9756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:58\n",
      "TrainLoss: 1.7437, TrainAcc: 0.4870\n",
      "ValidLoss: 2.2467, ValidAcc: 0.3753\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/64: 100%|██████████| 102/102 [00:28<00:00,  3.53it/s, batchLoss=2.1091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:59\n",
      "TrainLoss: 1.7084, TrainAcc: 0.4846\n",
      "ValidLoss: 2.7527, ValidAcc: 0.2988\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/64: 100%|██████████| 102/102 [00:32<00:00,  3.12it/s, batchLoss=1.2604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:60\n",
      "TrainLoss: 1.7025, TrainAcc: 0.4963\n",
      "ValidLoss: 3.0803, ValidAcc: 0.2556\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/64: 100%|██████████| 102/102 [00:30<00:00,  3.35it/s, batchLoss=2.6317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:61\n",
      "TrainLoss: 1.7007, TrainAcc: 0.4948\n",
      "ValidLoss: 3.0884, ValidAcc: 0.2914\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/64: 100%|██████████| 102/102 [00:32<00:00,  3.13it/s, batchLoss=1.8962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:62\n",
      "TrainLoss: 1.6670, TrainAcc: 0.5065\n",
      "ValidLoss: 2.6907, ValidAcc: 0.3185\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/64: 100%|██████████| 102/102 [00:33<00:00,  3.00it/s, batchLoss=1.2201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:63\n",
      "TrainLoss: 1.6560, TrainAcc: 0.5099\n",
      "ValidLoss: 2.3302, ValidAcc: 0.3679\n",
      "LR: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/64: 100%|██████████| 102/102 [00:30<00:00,  3.39it/s, batchLoss=1.7620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:64\n",
      "TrainLoss: 1.6107, TrainAcc: 0.5194\n",
      "ValidLoss: 2.3748, ValidAcc: 0.3889\n",
      "LR: 0.001000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    DATA_ROOT = (\n",
    "        \"D:/files/works/DeepLearning/experiment3/data/car-classificationproject-vision\"\n",
    "    )\n",
    "    train_loader, val_loader, test_loader, num_classes = setup_data_loaders(\n",
    "        data_root=DATA_ROOT,\n",
    "        image_size=224,\n",
    "        batch_size=32,\n",
    "        split_ratio=0.8,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    model = Model(\n",
    "        chns_in=3,\n",
    "        chns_base=64,\n",
    "        feats_base=1024,\n",
    "        dropout_rate=0.3,\n",
    "        ker_size=3,\n",
    "        nums_classes=num_classes,\n",
    "        padding=1,\n",
    "        stride=1,\n",
    "    ).to(device)\n",
    "    loss = Loss()\n",
    "    optimizer = Optimizer(model=model, lr=1e-3, weight_decay=1e-4)\n",
    "    train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = train(\n",
    "        model=model,\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=val_loader,\n",
    "        nnum_epoches=64,\n",
    "        device=device,\n",
    "        accumulation_steps=8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48728666",
   "metadata": {},
   "source": [
    "## 3 不同超参数的对比分析（包括卷积层数、卷积核大小、batchsize、lr等）选其中至少1-2个进行分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3214cfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de9fe64e",
   "metadata": {},
   "source": [
    "## 4 使用PyTorch实现经典模型AlexNet并在至少一个数据集进行试验分析 （无GPU环境则至少实现模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        chns_in: int,\n",
    "        chns_base: int,\n",
    "        feats_base: int,\n",
    "        nums_classes: int,\n",
    "        ker_size: int,\n",
    "        padding: int = 0,\n",
    "        stride: int = 1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.chns_in = chns_in\n",
    "        self.chns_base = chns_base\n",
    "        self.feats_base = feats_base\n",
    "        self.nums_classes = nums_classes\n",
    "        self.ker_size = ker_size\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # cov1\n",
    "            nn.Conv2d(\n",
    "                chns_in,\n",
    "                chns_base * 1,\n",
    "                kernel_size=ker_size,\n",
    "                padding=self.padding,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm2d(chns_base * 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # cov2\n",
    "            nn.Conv2d(\n",
    "                chns_base * 1,\n",
    "                chns_base * 2,\n",
    "                kernel_size=ker_size,\n",
    "                padding=self.padding,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm2d(chns_base * 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            # conv3\n",
    "            nn.Conv2d(\n",
    "                chns_base * 2,\n",
    "                chns_base * 4,\n",
    "                kernel_size=ker_size,\n",
    "                padding=self.padding,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm2d(chns_base * 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # conv4\n",
    "            nn.Conv2d(\n",
    "                chns_base * 4,\n",
    "                chns_base * 8,\n",
    "                kernel_size=ker_size,\n",
    "                padding=self.padding,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm2d(chns_base * 8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # conv5\n",
    "            nn.Conv2d(\n",
    "                chns_base * 8,\n",
    "                chns_base * 16,\n",
    "                kernel_size=ker_size,\n",
    "                padding=self.padding,\n",
    "                stride=self.stride,\n",
    "            ),\n",
    "            nn.BatchNorm2d(chns_base * 16),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.pool = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.chns_base * 16, self.feats_base),\n",
    "            nn.Linear(self.feats_base, self.nums_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        X = self.conv(X)\n",
    "        X = self.pool(X)\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = self.fc(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051c0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self) -> None:\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def calc(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return self.criterion(y_pred, y_true)\n",
    "\n",
    "    def __call__(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return self.calc(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2db46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, model: Model, lr: float = 0.01) -> None:\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr)\n",
    "\n",
    "    def step(self) -> None:\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def zero_grad(self) -> None:\n",
    "        self.optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246cb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model: Model, loss: Loss, data_loader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_nums = 0\n",
    "        data_loss_value, data_acc_value = 0, 0\n",
    "        for features, labels in data_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            predict = model(features)\n",
    "            loss_value = loss(predict, labels)\n",
    "\n",
    "            total_nums += len(labels)\n",
    "            data_loss_value += loss_value.item() * len(labels)\n",
    "            data_acc_value += (predict.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        data_loss_value /= total_nums\n",
    "        data_acc_value /= total_nums\n",
    "    return data_loss_value, data_acc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9231b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: Model,\n",
    "    loss: Loss,\n",
    "    optimizer: Optimizer,\n",
    "    train_loader: DataLoader,\n",
    "    valid_loader: DataLoader,\n",
    "    nnum_epoches: int,\n",
    "    device: torch.device,\n",
    "):\n",
    "    train_loss_list, train_acc_list = [], []\n",
    "    valid_loss_list, valid_acc_list = [], []\n",
    "    for epoch in range(nnum_epoches):\n",
    "        model.train()\n",
    "        total_nums = 0\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "        valid_loss, valid_acc = 0.0, 0.0\n",
    "        # 使用 tqdm 包裹 train_loader\n",
    "        # desc: 设置进度条前面的文字\n",
    "        # leave: 当前 Epoch 完成后是否保留进度条\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{nnum_epoches}\", leave=True)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # 计算预测值和损失值并优化\n",
    "            predict = model(images)\n",
    "            loss_value = loss(predict, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            # 统计数据\n",
    "            total_nums += len(labels)\n",
    "            train_loss += loss_value.item() * len(labels)\n",
    "            train_acc += (predict.argmax(dim=1) == labels).sum().item()\n",
    "            # 实时更新进度条右侧的显示信息\n",
    "            pbar.set_postfix({\"currentBatchLoss\": f\"{loss_value.item():.4f}\"})\n",
    "        # 计算整个 Epoch 的平均值\n",
    "        train_loss /= total_nums\n",
    "        train_acc /= total_nums\n",
    "        valid_loss, valid_acc = evaluation(model, loss, valid_loader, device)\n",
    "        # 3. 打印最终结果（在进度条完成后换行显示）\n",
    "        print(\n",
    "            f\"epoch:{epoch+1}\\n\\\n",
    "              TrainLoss: {train_loss:.4f}, TrainAcc: {train_acc:.4f}\\n\\\n",
    "              ValidLoss: {valid_loss:.4f}, ValidAcc: {valid_acc:.4f}\\n\"\n",
    "        )\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_acc_list.append(valid_acc)\n",
    "    return train_loss_list, train_acc_list, valid_loss_list, valid_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6daed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    DATA_ROOT = (\n",
    "        \"D:/files/works/DeepLearning/experiment3/data/car-classificationproject-vision\"\n",
    "    )\n",
    "    train_loader, val_loader, test_loader, num_classes = setup_data_loaders(\n",
    "        data_root=DATA_ROOT,\n",
    "        image_size=224,\n",
    "        batch_size=24,\n",
    "        split_ratio=0.8,\n",
    "        num_workers=4,\n",
    "    )\n",
    "    model = Model(\n",
    "        chns_in=3,\n",
    "        chns_base=64,\n",
    "        feats_base=1024,\n",
    "        ker_size=3,\n",
    "        nums_classes=45,\n",
    "        padding=1,\n",
    "        stride=1,\n",
    "    ).to(device)\n",
    "    loss = Loss()\n",
    "    optimizer = Optimizer(model=model, lr=0.003)\n",
    "    train_loss_list, train_acc_list, valid_loss_list, valid_acc_list = train(\n",
    "        model=model,\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=val_loader,\n",
    "        nnum_epoches=64,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b32e9b",
   "metadata": {},
   "source": [
    "## 5 使用实验2中的前馈神经网络模型在本次给定数据集上进行实验，并将实验结果与卷积模型结果进行对比分析（选做）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
